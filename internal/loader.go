package internal

import (
	"context"
	"fmt"
	"log"
	"time"
)

// LoadAllCachedData loads ALL existing cache combinations (regardless of age)
// without performing any network fetches. Returns only combinations with data.
func LoadAllCachedData(ctx context.Context) []TrackInfo {
	trackConfigs := GetTracks()
	classConfigs := GetCarClasses()

	dataCache := NewDataCache()

	totalCombinations := len(trackConfigs) * len(classConfigs)
	cached := make([]TrackInfo, 0, totalCombinations/2)

	for _, track := range trackConfigs {
		for _, class := range classConfigs {
			select {
			case <-ctx.Done():
				return cached
			default:
			}
			if dataCache.CacheExists(track.TrackID, class.ClassID) {
				trackInfo, err := dataCache.LoadTrackData(track.TrackID, class.ClassID)
				if err == nil && len(trackInfo.Data) > 0 {
					cached = append(cached, trackInfo)
				}
			}
		}
	}

	log.Printf("‚úÖ Loaded %d cached combinations for bootstrap indexing", len(cached))
	return cached
}

// LoadAllTrackData loads leaderboard data for all track+class combinations
func LoadAllTrackData(ctx context.Context) []TrackInfo {
	return LoadAllTrackDataWithCallback(ctx, nil, nil)
}

// LoadAllTrackDataWithCallback loads data and calls progressCallback periodically for status updates
func LoadAllTrackDataWithCallback(ctx context.Context, progressCallback func([]TrackInfo), cacheCompleteCallback func([]TrackInfo, bool)) []TrackInfo {
	// Observability: aggregate track activity during startup loading
	activity := NewTrackActivityReport()
	// Reset per-run dedup sets so counts reflect this run only
	ResetCachedLoads(&activity)
	ResetFetchedCounts(&activity, "startup")
	fetchTracker := NewFetchTracker()
	trackConfigs := GetTracks()
	classConfigs := GetCarClasses()

	log.Printf("üìä Loading data for %d tracks √ó %d classes = %d combinations...",
		len(trackConfigs), len(classConfigs), len(trackConfigs)*len(classConfigs))

	apiClient := NewAPIClient()
	defer apiClient.Close() // Ensure connections are cleaned up

	var allTrackData []TrackInfo
	dataCache := NewDataCache()      // For reading existing cache
	tempCache := NewTempDataCache()  // For writing new fetches
	defer tempCache.ClearTempCache() // Clean up temp cache on exit

	totalCombinations := len(trackConfigs) * len(classConfigs)

	// PHASE 1: Load ALL existing cache (even if expired)
	log.Println("üîÑ Phase 1: Loading all cached data...")
	cacheLoadCount := 0
	// Pre-allocate with estimated capacity to avoid repeated allocations
	allTrackData = make([]TrackInfo, 0, totalCombinations/2)
	for _, track := range trackConfigs {
		for _, class := range classConfigs {
			// Check if cancellation was requested
			select {
			case <-ctx.Done():
				log.Printf("üõë Cancelled during cache loading")
				return allTrackData
			default:
			}

			// Only load from cache, don't fetch
			if dataCache.CacheExists(track.TrackID, class.ClassID) {
				trackInfo, err := dataCache.LoadTrackData(track.TrackID, class.ClassID)
				if err == nil && len(trackInfo.Data) > 0 {
					allTrackData = append(allTrackData, trackInfo)
					cacheLoadCount++
					// Count cached unique class per track for this run
					IncrementCacheLoad(&activity, track.TrackID, track.Name, class.ClassID)
					// Export activity periodically during cache loading
					if cacheLoadCount%50 == 0 {
						if err := ExportTrackActivity(activity); err != nil {
							log.Printf("‚ö†Ô∏è Failed to export track activity during cache load: %v", err)
						}
					}
				}
			}
		}
	}

	log.Printf("‚úÖ Cache loaded: %d combinations", cacheLoadCount)
	// Persist activity after cache loading phase
	if err := ExportTrackActivity(activity); err != nil {
		log.Printf("‚ö†Ô∏è Failed to export track activity (cache phase): %v", err)
	}

	// PHASE 2: Check if we need to fetch
	needsFetching := false
	for _, track := range trackConfigs {
		for _, class := range classConfigs {
			if !dataCache.CacheExists(track.TrackID, class.ClassID) || dataCache.IsCacheExpired(track.TrackID, class.ClassID) {
				needsFetching = true
				break
			}
		}
		if needsFetching {
			break
		}
	}

	// Trigger cache complete callback with whether we'll fetch
	// Always invoke so orchestrator can decide to start periodic indexing
	if cacheCompleteCallback != nil {
		log.Printf("üìä Building initial index from %d cached combinations...", len(allTrackData))
		cacheCompleteCallback(allTrackData, needsFetching)
	}

	if !needsFetching {
		log.Println("‚úÖ All cache is fresh - no fetching needed")
		return allTrackData
	}

	// PHASE 3: Fetch missing and expired data
	log.Println("üîÑ Phase 2: Fetching missing and expired data...")
	fetchTracker.SaveFetchStart()

	currentCombination := 0
	fetchedCount := 0

	// Create a map of existing data for quick lookup
	existingData := make(map[string]TrackInfo)
	for _, track := range allTrackData {
		key := track.TrackID + "_" + track.ClassID
		existingData[key] = track
	}

	for _, track := range trackConfigs {
		for _, class := range classConfigs {
			currentCombination++

			// Check if cancellation was requested
			select {
			case <-ctx.Done():
				log.Printf("üõë Fetch cancelled at %d/%d combinations", currentCombination, totalCombinations)
				return allTrackData
			default:
			}

			key := track.TrackID + "_" + class.ClassID
			needsRefresh := !dataCache.CacheExists(track.TrackID, class.ClassID) || dataCache.IsCacheExpired(track.TrackID, class.ClassID)

			if !needsRefresh {
				// Already have fresh cache, skip
				continue
			}

			// Get cache age for logging
			cacheAge := dataCache.GetCacheAge(track.TrackID, class.ClassID)
			cacheAgeStr := "missing"
			if cacheAge >= 0 {
				// Format age nicely
				if cacheAge < time.Hour {
					cacheAgeStr = fmt.Sprintf("%.0fm", cacheAge.Minutes())
				} else if cacheAge < 24*time.Hour {
					cacheAgeStr = fmt.Sprintf("%.1fh", cacheAge.Hours())
				} else {
					cacheAgeStr = fmt.Sprintf("%.1fd", cacheAge.Hours()/24)
				}
			}

			// Show progress every 50 combinations
			if currentCombination%50 == 0 || currentCombination == 1 {
				if progressCallback != nil {
					progressCallback(allTrackData)
				}
			}

			// Fetch fresh data - always fetch (don't check cache) and write to tempCache
			// We use dataCache to check if cache exists/expired above, but write to tempCache
			data, duration, err := apiClient.FetchLeaderboardData(track.TrackID, class.ClassID)
			if err != nil {
				continue // Skip on fetch error
			}

			trackInfo := TrackInfo{
				Name:    track.Name,
				TrackID: track.TrackID,
				ClassID: class.ClassID,
				Data:    data,
			}

			// Always save to temp cache to update timestamp, even for empty data
			if saveErr := tempCache.SaveTrackData(trackInfo); saveErr != nil {
				log.Printf("‚ö†Ô∏è Warning: Could not save to temp cache %s + %s: %v", track.Name, class.Name, saveErr)
			}

			if len(data) > 0 {
				log.Printf("üåê %s + %s: %.2fs ‚Üí %d entries (cache age: %s) [track=%s, class=%s]", track.Name, class.Name, duration.Seconds(), len(data), cacheAgeStr, track.TrackID, class.ClassID)
			} else {
				log.Printf("üåê %s + %s: %.2fs ‚Üí no data (cache age: %s) [track=%s, class=%s]", track.Name, class.Name, duration.Seconds(), cacheAgeStr, track.TrackID, class.ClassID)
			}

			fromCache := false

			// Update or add the track data
			if len(trackInfo.Data) > 0 {
				existingData[key] = trackInfo
				fetchedCount++
				// Count unique fetch per track+class (startup origin)
				IncrementFetch(&activity, track.TrackID, track.Name, "startup", class.ClassID)

				// Update progress callback and export activity periodically
				if progressCallback != nil && fetchedCount%10 == 0 {
					// Rebuild allTrackData from map
					allTrackData = make([]TrackInfo, 0, len(existingData))
					for _, v := range existingData {
						allTrackData = append(allTrackData, v)
					}
					progressCallback(allTrackData)
					// Export activity to track progress
					if err := ExportTrackActivity(activity); err != nil {
						log.Printf("‚ö†Ô∏è Failed to export track activity during fetch: %v", err)
					}
				}
			}

			// Rate limiting for API calls
			if !fromCache {
				sleepDuration := 200 * time.Millisecond
				for i := 0; i < int(sleepDuration/time.Millisecond); i += 100 {
					select {
					case <-ctx.Done():
						log.Printf("üõë Fetch cancelled at %d/%d combinations", currentCombination, totalCombinations)
						// Rebuild final data from map
						allTrackData = make([]TrackInfo, 0, len(existingData))
						for _, v := range existingData {
							allTrackData = append(allTrackData, v)
						}
						return allTrackData
					default:
					}
					time.Sleep(100 * time.Millisecond)
				}
			}
		}
	}

	// Rebuild final allTrackData from map
	allTrackData = make([]TrackInfo, 0, len(existingData))
	for _, v := range existingData {
		allTrackData = append(allTrackData, v)
	}

	// Clean up temporary map to release memory
	existingData = nil

	// Promote temp cache to main cache atomically
	log.Println("üîÑ Promoting temporary cache to main cache...")
	promotedCount, err := tempCache.PromoteTempCache()
	if err != nil {
		log.Printf("‚ö†Ô∏è Critical error promoting temp cache: %v", err)
		// Continue anyway - we still have the in-memory data
	} else if promotedCount > 0 {
		log.Printf("‚úÖ Promoted %d cache files successfully", promotedCount)
	}

	fetchTracker.SaveFetchEnd()

	log.Printf("‚úÖ Loaded %d total combinations (%d from cache, %d fetched)",
		len(allTrackData), cacheLoadCount, fetchedCount)
	// Persist activity after fetch phase
	if err := ExportTrackActivity(activity); err != nil {
		log.Printf("‚ö†Ô∏è Failed to export track activity (fetch phase): %v", err)
	}
	return allTrackData
}

// ForceRefreshAllTracks forces a refresh of all track data, bypassing cache
func ForceRefreshAllTracks(ctx context.Context) []TrackInfo {
	fetchTracker := NewFetchTracker()
	fetchTracker.SaveFetchStart()

	// Clear existing cache to force fresh downloads
	dataCache := NewDataCache()
	if err := dataCache.ClearCache(); err != nil {
		log.Printf("‚ö†Ô∏è Warning: Could not clear cache: %v", err)
	}

	// Reload all track data (this will fetch fresh data since cache is cleared)
	result := LoadAllTrackData(ctx)

	fetchTracker.SaveFetchEnd()
	return result
}

// FetchAllTrackDataWithCallback forces fetching of ALL track+class combinations,
// bypassing cache reads entirely. It writes fresh data to a temporary cache
// and promotes it atomically at the end. Progress is reported via the callback.
func FetchAllTrackDataWithCallback(ctx context.Context, progressCallback func([]TrackInfo), origin string) []TrackInfo {
	fetchTracker := NewFetchTracker()
	trackConfigs := GetTracks()
	classConfigs := GetCarClasses()

	log.Printf("üìä Scheduled refresh: force-fetch %d tracks √ó %d classes = %d combinations...",
		len(trackConfigs), len(classConfigs), len(trackConfigs)*len(classConfigs))

	apiClient := NewAPIClient()
	defer apiClient.Close()

	tempCache := NewTempDataCache()
	defer tempCache.ClearTempCache()

	totalCombinations := len(trackConfigs) * len(classConfigs)
	allTrackData := make([]TrackInfo, 0, totalCombinations)

	fetchTracker.SaveFetchStart()
	// Observability: aggregate track activity during forced refresh
	activity := NewTrackActivityReport()
	// Reset fetched counts for the specific origin so they reflect this run
	ResetFetchedCounts(&activity, origin)

	processed := 0
	// Fetch ALL combinations unconditionally
	for _, track := range trackConfigs {
		for _, class := range classConfigs {
			processed++

			// Check cancellation
			select {
			case <-ctx.Done():
				log.Printf("üõë Fetch cancelled at %d/%d combinations", processed, totalCombinations)
				fetchTracker.SaveFetchEnd()
				return allTrackData
			default:
			}

			data, duration, err := apiClient.FetchLeaderboardData(track.TrackID, class.ClassID)
			if err != nil {
				// Log and continue on error to avoid losing large portions
				log.Printf("‚ö†Ô∏è Fetch error %s + %s: %v", track.Name, class.Name, err)
				// still report progress periodically
				if progressCallback != nil && (processed%50 == 0 || processed == 1) {
					progressCallback(allTrackData)
				}
				continue
			}

			ti := TrackInfo{
				Name:    track.Name,
				TrackID: track.TrackID,
				ClassID: class.ClassID,
				Data:    data,
			}

			// Always save to temp cache to update timestamp, even for empty data
			if saveErr := tempCache.SaveTrackData(ti); saveErr != nil {
				log.Printf("‚ö†Ô∏è Warning: Could not save to temp cache %s + %s: %v", track.Name, class.Name, saveErr)
			}

			// Append only if we have entries; keep empty combos out to avoid bloating
			if len(ti.Data) > 0 {
				allTrackData = append(allTrackData, ti)
				// Count unique fetch per track+class for this origin (nightly/manual)
				IncrementFetch(&activity, track.TrackID, track.Name, origin, class.ClassID)
			}

			if len(data) > 0 {
				log.Printf("üåê %s + %s: %.2fs ‚Üí %d entries [track=%s, class=%s]",
					track.Name, class.Name, duration.Seconds(), len(data), track.TrackID, class.ClassID)
			} else {
				log.Printf("üåê %s + %s: %.2fs ‚Üí no data [track=%s, class=%s]",
					track.Name, class.Name, duration.Seconds(), track.TrackID, class.ClassID)
			}

			// Periodic progress updates and activity export
			if progressCallback != nil && (processed%50 == 0 || processed == 1) {
				progressCallback(allTrackData)
			}
			// Export activity every 50 fetches to track progress
			if processed%50 == 0 {
				if err := ExportTrackActivity(activity); err != nil {
					log.Printf("‚ö†Ô∏è Failed to export track activity during refresh: %v", err)
				}
			}

			// Rate limit API calls
			sleepDuration := 200 * time.Millisecond
			for i := 0; i < int(sleepDuration/time.Millisecond); i += 100 {
				select {
				case <-ctx.Done():
					log.Printf("üõë Fetch cancelled at %d/%d combinations", processed, totalCombinations)
					fetchTracker.SaveFetchEnd()
					return allTrackData
				default:
				}
				time.Sleep(100 * time.Millisecond)
			}
		}
	}

	// Promote temp cache to main cache atomically
	log.Println("üîÑ Promoting temporary cache to main cache...")
	promotedCount, err := tempCache.PromoteTempCache()
	if err != nil {
		log.Printf("‚ö†Ô∏è Critical error promoting temp cache: %v", err)
	} else if promotedCount > 0 {
		log.Printf("‚úÖ Promoted %d cache files successfully", promotedCount)
	}

	fetchTracker.SaveFetchEnd()
	// Persist activity after forced refresh
	if err := ExportTrackActivity(activity); err != nil {
		log.Printf("‚ö†Ô∏è Failed to export track activity (forced refresh): %v", err)
	}
	log.Printf("‚úÖ Force-fetched %d combinations (kept %d with data)", totalCombinations, len(allTrackData))
	return allTrackData
}
